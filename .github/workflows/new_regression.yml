name: Parallel Jobs per File (ops + uat with env)

on:
  workflow_dispatch:

# YAML anchors to reduce duplication
x-chunk-job: &chunk-job
  runs-on: ubuntu-latest
  env:
    CMR_USER: ${{ secrets.CMR_USER }}
    CMR_PASS: ${{ secrets.CMR_PASS }}
  strategy:
    max-parallel: 3
    fail-fast: false
  steps:
    - name: Print env and file
      run: echo "Env=${{ matrix.env }} File=${{ matrix.file }}"
    - uses: actions/checkout@v4
    - uses: actions/setup-python@v5
      with:
        python-version: "3.10"
    - uses: abatilo/actions-poetry@v3
      with:
        poetry-version: 2.1.3
    - run: poetry install
    - name: Run Regression
      working-directory: tests
      run: poetry run pytest verify_collection.py --env ${{ matrix.env }} --concept_id ${{ matrix.file }}

jobs:
  generate-chunks:
    runs-on: ubuntu-latest
    outputs:
      chunk1: ${{ steps.set.outputs.chunk1 }}
      chunk2: ${{ steps.set.outputs.chunk2 }}
      chunk3: ${{ steps.set.outputs.chunk3 }}
      chunk4: ${{ steps.set.outputs.chunk4 }}
      chunk5: ${{ steps.set.outputs.chunk5 }}
    steps:
      - uses: actions/checkout@v4
      - id: set
        run: |
          shopt -s nullglob
          files=(tests/cmr/l2ss-py/ops/* tests/cmr/l2ss-py/uat/*)
          total=${#files[@]}
          chunk_size=250  # Stay under 256 matrix limit
          chunk_size=3

          num_chunks=$(( (total + chunk_size - 1) / chunk_size ))
          
          for i in $(seq 0 $((num_chunks - 1))); do
            [ $i -ge 5 ] && break  # Max 5 chunks
            
            start=$((i * chunk_size))
            chunk=("${files[@]:start:chunk_size}")
            
            [ ${#chunk[@]} -eq 0 ] && continue
            
            json=$(printf '%s\n' "${chunk[@]}" \
              | jq -R 'split("/") | {env: .[-2], file: .[-1]}' \
              | jq -s '{include: .}')
            
            {
              echo "chunk$((i+1))<<EOF"
              echo "$json"
              echo "EOF"
            } >> "$GITHUB_OUTPUT"
          done

  process-chunk-1:
    <<: *chunk-job
    needs: generate-chunks
    if: needs.generate-chunks.outputs.chunk1 != ''
    strategy:
      max-parallel: 3
      fail-fast: false
      matrix: ${{ fromJson(needs.generate-chunks.outputs.chunk1) }}

  process-chunk-2:
    <<: *chunk-job
    needs: generate-chunks
    if: needs.generate-chunks.outputs.chunk2 != ''
    strategy:
      max-parallel: 3
      fail-fast: false
      matrix: ${{ fromJson(needs.generate-chunks.outputs.chunk2) }}

  process-chunk-3:
    <<: *chunk-job
    needs: generate-chunks
    if: needs.generate-chunks.outputs.chunk3 != ''
    strategy:
      max-parallel: 3
      fail-fast: false
      matrix: ${{ fromJson(needs.generate-chunks.outputs.chunk3) }}

  process-chunk-4:
    <<: *chunk-job
    needs: generate-chunks
    if: needs.generate-chunks.outputs.chunk4 != ''
    strategy:
      max-parallel: 3
      fail-fast: false
      matrix: ${{ fromJson(needs.generate-chunks.outputs.chunk4) }}

  process-chunk-5:
    <<: *chunk-job
    needs: generate-chunks
    if: needs.generate-chunks.outputs.chunk5 != ''
    strategy:
      max-parallel: 3
      fail-fast: false
      matrix: ${{ fromJson(needs.generate-chunks.outputs.chunk5) }}