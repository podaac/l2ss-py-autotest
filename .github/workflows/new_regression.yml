name: Regression Parallel Jobs (OPS & UAT)

on:
  schedule:
    # Run OPS every 3 days at midnight PST (8 AM UTC)
    - cron: '0 8 */3 * *'
    # Run UAT every 3 days at 4 AM PST (12 PM UTC)
    - cron: '0 12 */3 * *'
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment to test'
        required: true
        type: choice
        options:
          - ops
          - uat

jobs:
  setup-and-chunk:
    runs-on: ubuntu-latest
    outputs:
      environment: ${{ steps.prepare.outputs.environment }}
      environment_upper: ${{ steps.prepare.outputs.environment_upper }}
      matrix_chunks: ${{ steps.prepare.outputs.matrix_chunks }}
    steps:
      - uses: actions/checkout@v4
      
      - name: Determine Environment & Generate Chunks
        id: prepare
        run: |
          # 1. Determine Environment
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            ENV="${{ inputs.environment }}"
          elif [ "${{ github.event.schedule }}" = "0 8 */3 * *" ]; then
            ENV="ops"
          else
            ENV="uat"
          fi
          
          echo "environment=$ENV" >> "$GITHUB_OUTPUT"
          echo "environment_upper=${ENV^^}" >> "$GITHUB_OUTPUT"

          # 2. Chunk Files
          shopt -s nullglob
          files=(tests/cmr/l2ss-py/${ENV}/*)
          total=${#files[@]}

          # Handle 0 files gracefully
          if [ "$total" -eq 0 ]; then
            echo "No files found for environment $ENV!"
            echo "matrix_chunks=[]" >> "$GITHUB_OUTPUT"
            exit 0
          fi

          max_chunk_size=250
          num_chunks=8

          # Compute dynamic chunk size
          chunk_size=$(( (total + num_chunks - 1) / num_chunks ))

          # Enforce the maximum
          if (( chunk_size > max_chunk_size )); then
            chunk_size=$max_chunk_size
            num_chunks=$(( (total + chunk_size - 1) / chunk_size ))
          fi

          echo "Total files: $total"
          echo "Chunk size: $chunk_size"
          echo "Chunks: $num_chunks"

          # Generate a single JSON array of all chunks for the Matrix
          chunks_json=$(
            for i in $(seq 0 $((num_chunks - 1))); do
              start=$((i * chunk_size))
              chunk=("${files[@]:start:chunk_size}")
              
              [ ${#chunk[@]} -eq 0 ] && continue
              
              # Output each chunk as a discrete JSON object
              printf '%s\n' "${chunk[@]}" \
                | jq -R 'split("/") | {env: .[-2], file: .[-1]}' \
                | jq -s '{include: .}'
            done | jq -s -c '.' # Slurp all objects into one valid JSON array
          )

          echo "matrix_chunks=$chunks_json" >> "$GITHUB_OUTPUT"

  process-chunks:
    needs: setup-and-chunk
    # Only run if there are actual chunks to process
    if: ${{ needs.setup-and-chunk.outputs.matrix_chunks != '[]' && needs.setup-and-chunk.outputs.matrix_chunks != '' }}
    strategy:
      fail-fast: false
      matrix:
        # Dynamically spawn exactly as many jobs as we have chunks
        chunk: ${{ fromJson(needs.setup-and-chunk.outputs.matrix_chunks) }}
    uses: ./.github/workflows/process_chunk.yml
    secrets: inherit
    with:
      # Pass the specific matrix payload as a JSON string
      chunk-data: ${{ toJSON(matrix.chunk) }}
      environment: ${{ needs.setup-and-chunk.outputs.environment_upper }}

  aggregate-failures:
    needs: [setup-and-chunk, process-chunks]
    runs-on: ubuntu-latest
    if: always()
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install Poetry
        uses: abatilo/actions-poetry@v3
        with:
          poetry-version: 2.1.3

      - name: Poetry Install
        run: poetry install

      - name: Download all job status artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: job-status-*
          path: job-status

      - name: Aggregate failed jobs and print URLs and reasons
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          GITHUB_REPOSITORY: ${{ github.repository }}
          REGRESSION_ENV: ${{ needs.setup-and-chunk.outputs.environment_upper }}
          CMR_USER: ${{ secrets.CMR_USER }}
          CMR_PASS: ${{ secrets.CMR_PASS }}
          OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}
        run: |
          poetry run python tests/aggregate_results.py